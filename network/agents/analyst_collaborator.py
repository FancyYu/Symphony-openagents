#!/usr/bin/env python3
"""
Analyst Collaborator - åˆ†æå¸ˆåä½œ Agent
ä½¿ç”¨ CollaboratorAgent å®ç°ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ messaging mod
"""

import asyncio
import os
import sys
import json
from pathlib import Path
from typing import List

sys.path.insert(0, str(Path(__file__).parent.parent))

from openagents.agents.collaborator_agent import CollaboratorAgent
from openagents.models.agent_config import AgentConfig
from storage.memory_palace import memory_palace
from storage.framework_library import framework_library
from storage.simple_storage import storage


class AnalystCollaborator(CollaboratorAgent):
    """åˆ†æå¸ˆåä½œ Agent - æ¥æ”¶åˆ†æè¯·æ±‚ï¼Œè¿”å›æ´å¯Ÿ"""
    
    def __init__(self):
        config = AgentConfig(
            instruction="""You are an Analyst Agent in the Symphony personal growth system.

Your role:
- Receive analysis requests from other agents
- Analyze user messages for patterns, concerns, and growth opportunities
- Generate insights using various frameworks (HUMAN 3.0, MBTI, Big Five, etc.)
- Return structured analysis results

When you receive a message with analysis request:
1. Extract the content and framework
2. Apply the framework to analyze
3. Generate 3-5 key insights
4. Return results in JSON format

Be thorough, empathetic, and evidence-based.""",
            model_name="llama-3.1-8b-instant",
            provider="groq",
            api_key=os.getenv("GROQ_API_KEY"),
            api_base="https://api.groq.com/openai/v1",
            temperature=0.7,
            max_tokens=800
        )
        super().__init__(agent_config=config, agent_id="analyst-agent")
        
        print(f"ğŸ”¬ åˆ†æå¸ˆåä½œ Agent '{self.agent_id}' å·²åˆ›å»º")
    
    async def on_direct(self, msg):
        """å¤„ç†ç›´æ¥æ¶ˆæ¯ - åˆ†æè¯·æ±‚"""
        print(f"\nğŸ“Š æ”¶åˆ°åˆ†æè¯·æ±‚ from {msg.sender_id}")
        
        # è§£æè¯·æ±‚
        try:
            if isinstance(msg.text, str):
                request = json.loads(msg.text)
            else:
                request = msg.text
            
            user_id = request.get("user_id", "unknown")
            content = request.get("content", "")
            framework_name = request.get("framework", "general")
            channel = request.get("channel", "general")
            
            print(f"   ç”¨æˆ·: {user_id}")
            print(f"   æ¡†æ¶: {framework_name}")
            print(f"   å†…å®¹: {content[:100]}...")
            
            # æ‰§è¡Œåˆ†æ
            insights = await self.perform_analysis(content, framework_name, user_id)
            
            # ä¿å­˜åˆ†æç»“æœ
            storage.save_analysis(
                user_id=user_id,
                framework=framework_name,
                insights=insights,
                confidence=0.8
            )
            
            # ä¿å­˜åˆ°è®°å¿†æ®¿å ‚
            keywords = self._extract_keywords(content, framework_name)
            memory_palace.add_long_term_memory(
                user_id=user_id,
                memory_type="analysis",
                content=f"Framework: {framework_name}\nInsights: {json.dumps(insights, ensure_ascii=False)}",
                keywords=keywords,
                importance=0.8,
                metadata={"framework": framework_name}
            )
            
            print(f"   âœ… åˆ†æå®Œæˆ: {len(insights)} ä¸ªæ´å¯Ÿ")
            
            # è¿”å›ç»“æœç»™å‘é€è€…
            result = {
                "user_id": user_id,
                "framework": framework_name,
                "channel": channel,
                "insights": insights,
                "confidence": 0.8,
                "original_content": content
            }
            
            ws = self.workspace()
            await ws.agent(msg.sender_id).send(json.dumps(result, ensure_ascii=False))
            print(f"   ğŸ“¤ å·²è¿”å›åˆ†æç»“æœç»™ {msg.sender_id}")
            
        except Exception as e:
            print(f"   âŒ åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    async def perform_analysis(self, content: str, framework_name: str, user_id: str) -> List[str]:
        """æ‰§è¡Œåˆ†æ"""
        # ä»è®°å¿†æ®¿å ‚è·å–ä¸Šä¸‹æ–‡
        context_data = memory_palace.build_context(user_id, current_topic=content)
        
        # è·å–æ¡†æ¶ä¿¡æ¯
        framework = framework_library.get_framework(framework_name)
        if not framework:
            framework = framework_library.get_framework("general")
        
        # æ„å»ºåˆ†ææç¤º
        prompt = f"""Analyze the following user message using the {framework.name} framework.

Framework Description: {framework.description}

Framework Dimensions:
{chr(10).join(f"- {dim}" for dim in framework.dimensions)}

Analysis Guidelines:
{framework_library.get_analysis_prompt(framework_name)}

User message: {content}

User Context:
- Total interactions: {len(context_data['recent_memories'])}
- Previous frameworks used: {json.loads(context_data['profile'].get('frameworks_used', '[]'))}

Recent relevant memories:
{self._format_memories(context_data['recent_memories'][:3])}

Generate 3-5 key insights. Each insight should be:
- Specific and actionable
- Based on the framework principles
- Focused on personal growth opportunities
- Written in a supportive, empathetic tone

Format as a numbered list in Chinese."""

        # ä½¿ç”¨ LLM ç”Ÿæˆåˆ†æ
        response = await self.run_agent(prompt)
        
        # è§£æå“åº”ä¸ºæ´å¯Ÿåˆ—è¡¨
        insights = self._parse_insights(response)
        
        return insights
    
    def _format_memories(self, memories: List[dict]) -> str:
        """æ ¼å¼åŒ–è®°å¿†"""
        if not memories:
            return "æ— å†å²è®°å½•"
        
        formatted = []
        for mem in memories:
            content = mem.get('content', '')[:100]
            formatted.append(f"- {content}")
        
        return "\n".join(formatted)
    
    def _extract_keywords(self, content: str, framework: str) -> List[str]:
        """æå–å…³é”®è¯"""
        keywords = [framework.lower()]
        
        import re
        words = re.findall(r'\w+', content.lower())
        
        stopwords = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}
        
        for word in words:
            if word not in stopwords and len(word) > 1:
                keywords.append(word)
                if len(keywords) >= 8:
                    break
        
        return keywords
    
    def _parse_insights(self, response: str) -> List[str]:
        """è§£æ LLM å“åº”ä¸ºæ´å¯Ÿåˆ—è¡¨"""
        insights = []
        lines = response.split('\n')
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#'):
                import re
                line = re.sub(r'^\d+[\.\)]\s*', '', line)
                line = re.sub(r'^[-â€¢]\s*', '', line)
                if line and len(line) > 10:
                    insights.append(line)
        
        if not insights:
            insights = [line.strip() for line in lines[:5] if line.strip() and len(line.strip()) > 10]
        
        return insights[:5]


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨åˆ†æå¸ˆåä½œ Agent...")
    
    agent = AnalystCollaborator()
    
    try:
        await agent.async_start(
            network_host="localhost",
            network_port=8700,
            secret="",  # ç©º secret ç”¨äºæ— è®¤è¯ç½‘ç»œ
        )
        
        print(f"\nâœ… åˆ†æå¸ˆåä½œ Agent '{agent.agent_id}' æ­£åœ¨è¿è¡Œ")
        print("ğŸ“¡ ç­‰å¾…åˆ†æè¯·æ±‚ï¼ˆé€šè¿‡ç›´æ¥æ¶ˆæ¯ï¼‰")
        print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢\n")
        
        while True:
            await asyncio.sleep(1)
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ åœæ­¢ä¸­...")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await agent.async_stop()


if __name__ == "__main__":
    asyncio.run(main())
